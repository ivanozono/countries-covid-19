{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "In this initial section of the notebook, we establish the context and objectives of the data processing stage within our project. This notebook is crucial as a bridge between the acquisition of raw data and its detailed analysis and subsequent modeling. Here, we focus on understanding and preparing our data to ensure that it is of the highest quality and in a format suitable for advanced analysis.\n",
    "\n",
    "The main objectives of this notebook include:\n",
    "\n",
    "1. **Understanding the Dataset:** Gaining a clear view of the structure, content, and peculiarities of the data we have collected.\n",
    "\n",
    "2. **Data Preparation:** Implementing cleaning and transformation steps to convert raw data into a more usable and meaningful format for future analysis.\n",
    "\n",
    "3. **Establishing a Solid Foundation for Analysis:** Ensuring that the data is ready and accessible for performing statistical analyses, visualizations, and data modeling in the next steps of our project.\n",
    "\n",
    "By the end of this process, we will have a clean, organized, and well-documented dataset, ready for in-depth exploration and analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this section of the notebook, we import three key libraries that are fundamental to our data cleaning and preparation process:\n",
    "\n",
    "1. **Importing Project's Paths Module (`paths`):**\n",
    "   - `import final_project.utils.paths as path`:\n",
    "     - Here, we import the `paths` module from the `final_project.utils` package. This module is used for managing file and directory paths within the project, which facilitates organized and coherent path management. Importing it as `path` allows us to access these predefined paths more simply and directly.\n",
    "\n",
    "2. **Importing the `janitor` Library:**\n",
    "   - `import janitor`:\n",
    "     - `janitor` is a library that provides data cleaning functions for Pandas, making common data cleaning tasks easier and improving code readability. These functions include, among others, cleaning column names, removing duplicate rows, and managing missing values.\n",
    "\n",
    "3. **Importing Pandas:**\n",
    "   - `import pandas as pd`:\n",
    "     - Pandas is an essential library in data science for manipulating and analyzing data in Python. Its main data structure, the DataFrame, allows for easy manipulation of tabular data with numerous operations for filtering, sorting, and summarizing.\n",
    "\n",
    "These libraries form the foundation of our data processing environment, enabling us to efficiently handle data from loading to cleaning and preparing it for subsequent analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanozono/anaconda3/envs/final_project/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import final_project.utils.paths as path\n",
    "import janitor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- `input_covid_file = path.data_raw_dir(\"time_series_covid19_confirmed_global.csv\")`:\n",
    "  - We are defining the variable `input_covid_file`, which will be used to store the path to the raw COVID-19 data file.\n",
    "  - The function `data_raw_dir` from the `path` module (previously imported) is used here. This function, a part of our projectâ€™s path management structure, is designed to return the complete path to the specific directory where raw data is stored.\n",
    "  - We pass the file name `\"time_series_covid19_confirmed_global.csv\"` as an argument to the function, indicating that we are interested in the path to this specific file.\n",
    "  - This practice ensures a coherent and centralized management of file paths in the project, improving reproducibility and reducing errors caused by hard-coded file paths.\n",
    "\n",
    "The use of this `input_covid_file` variable in later stages of the notebook will allow us to load and manipulate the COVID-19 data easily and accurately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_covid_file = path.data_raw_dir(\"time_series_covid19_confirmed_global.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading and Initial Review of the COVID-19 Data\n",
    "\n",
    "- `covid_df = pd.read_csv(input_covid_file)`:\n",
    "  - In this line, we use the `read_csv` function from Pandas to load the COVID-19 data into a DataFrame named `covid_df`.\n",
    "  - The variable `input_covid_file`, which contains the path to the raw data file, is used as an argument, ensuring that we are loading the correct file.\n",
    "  - This is a crucial step in data processing, where we transform the raw data stored in a CSV file into a DataFrame structure, which is more versatile and convenient for analysis in Python.\n",
    "\n",
    "- `covid_df.info()`:\n",
    "  - This method provides essential information about the `covid_df` DataFrame, including the number of entries, the name of each column, the number of non-null values, and the data type of each column.\n",
    "  - It is a standard practice in data analysis to get a quick overview of the structure and integrity of the newly loaded data.\n",
    "  - This information helps us to plan the next steps in data processing, such as identifying columns that require cleaning, converting data types, or handling missing values.\n",
    "\n",
    "These two lines of code represent the start of our data analysis, providing a solid foundation for the data cleaning and exploration tasks that will follow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289 entries, 0 to 288\n",
      "Columns: 1147 entries, Province/State to 3/9/23\n",
      "dtypes: float64(2), int64(1143), object(2)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "covid_df = pd.read_csv(input_covid_file)\n",
    "covid_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Result of `covid_df.info()`\n",
    "\n",
    "The output from executing `covid_df.info()` on our DataFrame `covid_df` provides valuable information about the structure and content of the COVID-19 data:\n",
    "\n",
    "- **Class Type:** The DataFrame is of type `<class 'pandas.core.frame.DataFrame'>`, confirming that the data is stored in the standard DataFrame structure of Pandas.\n",
    "\n",
    "- **Row Index:** `RangeIndex: 289 entries, 0 to 288` indicates that the DataFrame contains 289 rows, starting at index 0 and ending at index 288. This gives an idea of the data volume.\n",
    "\n",
    "- **Columns:** There are `1147` columns in the DataFrame. The first column mentioned is `Province/State`, and the last is a date `3/9/23`. This suggests that the data includes multiple columns, likely representing time series of confirmed COVID-19 cases.\n",
    "\n",
    "- **Data Types:**\n",
    "  - `float64(2)`: There are 2 columns with float data types (decimal numbers).\n",
    "  - `int64(1143)`: The majority of the columns, 1143 in total, are of the integer type, which is consistent with the counting of confirmed cases.\n",
    "  - `object(2)`: There are 2 columns categorized as 'object', which are typically strings or mixed data.\n",
    "\n",
    "- **Memory Usage:** `memory usage: 2.5+ MB` indicates that the DataFrame occupies approximately 2.5 MB in memory. This is a useful metric for assessing memory storage efficiency and can influence the selection of data processing methods.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the First Rows of the COVID-19 DataFrame\n",
    "\n",
    "- `covid_df.head()`:\n",
    "  - This method is used to display the first five rows of the `covid_df` DataFrame, which contains the COVID-19 data.\n",
    "  - It is a common practice in data exploration to get a quick understanding of the data format, the included columns, and the style of the recorded data.\n",
    "  - Viewing the first few rows helps to confirm that the data has been loaded correctly and provides a preliminary view of the data structure, including column names, data types, and potential patterns or inconsistencies that might require attention in data cleaning and processing.\n",
    "\n",
    "The output of this command will be crucial for our initial data processing decisions, allowing us to adequately plan the next stages of cleaning, transforming, and analyzing the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/28/23</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "      <th>3/5/23</th>\n",
       "      <th>3/6/23</th>\n",
       "      <th>3/7/23</th>\n",
       "      <th>3/8/23</th>\n",
       "      <th>3/9/23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209322</td>\n",
       "      <td>209340</td>\n",
       "      <td>209358</td>\n",
       "      <td>209362</td>\n",
       "      <td>209369</td>\n",
       "      <td>209390</td>\n",
       "      <td>209406</td>\n",
       "      <td>209436</td>\n",
       "      <td>209451</td>\n",
       "      <td>209451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>334391</td>\n",
       "      <td>334408</td>\n",
       "      <td>334408</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334443</td>\n",
       "      <td>334457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>271441</td>\n",
       "      <td>271448</td>\n",
       "      <td>271463</td>\n",
       "      <td>271469</td>\n",
       "      <td>271469</td>\n",
       "      <td>271477</td>\n",
       "      <td>271477</td>\n",
       "      <td>271490</td>\n",
       "      <td>271494</td>\n",
       "      <td>271496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47866</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47875</td>\n",
       "      <td>47890</td>\n",
       "      <td>47890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>105255</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105277</td>\n",
       "      <td>105288</td>\n",
       "      <td>105288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
       "0        0        0        0        0  ...   209322  209340  209358  209362   \n",
       "1        0        0        0        0  ...   334391  334408  334408  334427   \n",
       "2        0        0        0        0  ...   271441  271448  271463  271469   \n",
       "3        0        0        0        0  ...    47866   47875   47875   47875   \n",
       "4        0        0        0        0  ...   105255  105277  105277  105277   \n",
       "\n",
       "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
       "0  209369  209390  209406  209436  209451  209451  \n",
       "1  334427  334427  334427  334427  334443  334457  \n",
       "2  271469  271477  271477  271490  271494  271496  \n",
       "3   47875   47875   47875   47875   47890   47890  \n",
       "4  105277  105277  105277  105277  105288  105288  \n",
       "\n",
       "[5 rows x 1147 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of `covid_df.head()`\n",
    "\n",
    "The output from `covid_df.head()` shows the first five rows of our COVID-19 dataset:\n",
    "\n",
    "- **Column Descriptions:**\n",
    "  - `Province/State`: This column contains the names of provinces or states. It appears to have many missing values (NaN), indicating that the data may be reported at the country level for these entries.\n",
    "  - `Country/Region`: The country or region to which the data row corresponds.\n",
    "  - `Lat` and `Long`: These columns represent the latitude and longitude coordinates of the country or region.\n",
    "  - Date Columns (`1/22/20`, `1/23/20`, ..., `3/9/23`): Each of these columns represents the number of confirmed COVID-19 cases on a specific date. The dataset appears to be a time series starting from January 22, 2020, to March 9, 2023.\n",
    "\n",
    "- **Row Examples:**\n",
    "  - The first row corresponds to Afghanistan, with latitude and longitude values and a time series of confirmed cases from January 22, 2020, to March 9, 2023.\n",
    "  - Similar patterns are observed for Albania, Algeria, Andorra, and Angola, with the progression of confirmed cases over time.\n",
    "\n",
    "- **Initial Observations:**\n",
    "  - The dataset is comprehensive, covering a wide date range and including many countries.\n",
    "  - The presence of NaN values in the `Province/State` column might require attention, depending on the analysis's goals.\n",
    "  - The data is primarily integer counts of confirmed cases, with geographical coordinates provided for each country or region.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following block of code represents a series of data transformation operations applied to the original `covid_df` DataFrame to create a new `processed_df` DataFrame, which is more structured and prepared for analysis:\n",
    "\n",
    "- `processed_df = (`\n",
    "  - We are defining `processed_df` as the result of a chain of methods applied to `covid_df`.\n",
    "\n",
    "- `.select_columns([\"Country/Region\", \"*/*/*\"])`\n",
    "  - We use the `select_columns` method to select specific columns from the DataFrame. We are selecting the `Country/Region` column and all columns that follow a date pattern (indicated by `*/*/*`), which  means all the time-series columns.\n",
    "\n",
    "- `.pivot_longer(index=\"Country/Region\", names_to=\"date\")`\n",
    "  - We apply `pivot_longer` to transform the DataFrame from a wide format to a long format. This method places each date as a row instead of a column, facilitating time-series analysis. The `Country/Region` column is kept as an index.\n",
    "\n",
    "- `.transform_column(\"date\", pd.to_datetime)`\n",
    "  - We transform the `date` column to a date and time format using `pd.to_datetime`. This is essential for later manipulations and analyses that require date-based operations.\n",
    "\n",
    "- `.clean_names()`\n",
    "  - Finally, `clean_names` is used to normalize and clean up the column names, ensuring consistency and improving the readability of the DataFrame.\n",
    "\n",
    "\n",
    "\n",
    "- `processed_df.head()`\n",
    "  - This method will show us the first five rows of the `processed_df` DataFrame, providing a quick view of the result of the transformation operations applied.\n",
    "\n",
    "This transformation process is crucial for preparing the data for more complex and efficient analyses, as it facilitates the handling of time series and ensures that the data is in a suitable and consistent format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_region</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_region       date  value\n",
       "0    Afghanistan 2020-01-22      0\n",
       "1        Albania 2020-01-22      0\n",
       "2        Algeria 2020-01-22      0\n",
       "3        Andorra 2020-01-22      0\n",
       "4         Angola 2020-01-22      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = (\n",
    "    covid_df\n",
    "    .select_columns([\"Country/Region\", \"*/*/*\"])\n",
    "    .pivot_longer(\n",
    "        index=\"Country/Region\",\n",
    "        names_to=\"date\"\n",
    "    )\n",
    "    .transform_column(\"date\", pd.to_datetime)\n",
    "    .clean_names()\n",
    ")\n",
    "\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of `processed_df.head()`\n",
    "\n",
    "The output from `processed_df.head()` presents the first five rows of our transformed DataFrame `processed_df`, which now reflects the structured format suitable for detailed analysis:\n",
    "\n",
    "- **Columns Description:**\n",
    "  - `country_region`: This column lists the country or region names. The transformation has standardized the column name for clarity and consistency.\n",
    "  - `date`: Represents the date for the corresponding data entry. The transformation process has converted this column to a proper date format, which is evident from the standardized date entries (e.g., `2020-01-22`).\n",
    "  - `value`: This column shows the number of confirmed COVID-19 cases. The pivot operation has transformed the original wide format (where each date was a separate column) into this long format, placing the count of confirmed cases in a single column.\n",
    "\n",
    "- **First Five Rows:**\n",
    "  - The rows display data for `Afghanistan`, `Albania`, `Algeria`, `Andorra`, and `Angola` for the date `2020-01-22`.\n",
    "  - Each row corresponds to the confirmed COVID-19 case count for each country on that date, which, in these cases, is `0`.\n",
    "\n",
    "- **Initial Observations:**\n",
    "  - The dataset now provides a streamlined view, with each row representing a single date entry for a country, making it easier to perform time-series analysis.\n",
    "  - The cleanliness and structure of the dataset have been significantly improved, with clear, consistent column names and well-organized data.\n",
    "\n",
    "This format of the data is highly beneficial for subsequent analyses, as it allows for more straightforward manipulation and analysis, particularly when dealing with time-series data across different countries or regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- `output_covid_file = path.data_processed_dir(\"time_series_covid19_confirmed_global_processed.csv\")`:\n",
    "  - In this line, we are defining the variable `output_covid_file`, which will store the output path for the processed COVID-19 data file.\n",
    "  - We use the `data_processed_dir` function from the `path` module to obtain the path to the specific directory intended for storing processed data within the project's structure.\n",
    "  - The file name `\"time_series_covid19_confirmed_global_processed.csv\"` indicates that we will save the processed data in a CSV file. \n",
    "Specifying this output path is an important step in organizing and managing data files within the project, ensuring that the processed data is easily accessible and well-organized for use in subsequent analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_covid_file = path.data_processed_dir(\"time_series_covid19_confirmed_global_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Processed Data to a CSV File\n",
    "\n",
    "- `processed_df.to_csv(output_covid_file, index=False)`:\n",
    "  - This line of code performs the final action of exporting the `processed_df` DataFrame to a CSV file.\n",
    "  - We use the `to_csv` method from Pandas, which is an efficient and straightforward way to save DataFrames in CSV format.\n",
    "  - `output_covid_file` is used as the file path argument, indicating where the CSV file will be saved. This is the path we defined earlier, ensuring that the data is stored in the correct location within our project's structure.\n",
    "  - The parameter `index=False` is included to indicate that we do not want to save the DataFrame's index in the CSV file. This is commonly preferred to keep data files clean and focused exclusively on the data, without additional index columns.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv(output_covid_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final step completes the data handling process in this notebook, ensuring that the processed data is available for immediate use in subsequent analyses or for sharing with other stakeholders of the project."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3201167444dbe6abbbc1aebe26fb7a6b7b946dd39b7e90e38c96f1716eb7be4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('final_project': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
